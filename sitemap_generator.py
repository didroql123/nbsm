import feedparser
from datetime import datetime
import html
import os
import re
from urllib.parse import quote

rss_url = "https://rss.blog.naver.com/rudtn668.xml"
base_url = "https://didroql123.github.io/nbsm"

print("ğŸ“¡ RSS í”¼ë“œ ë¡œë”© ì¤‘...")
feed = feedparser.parse(rss_url)
print(f"âœ… í”¼ë“œ ë¡œë”© ì™„ë£Œ, ê¸€ ìˆ˜: {len(feed.entries)}")

os.makedirs("posts", exist_ok=True)
print("ğŸ“ 'posts/' í´ë” ì¤€ë¹„ ì™„ë£Œ")

urls = [f"{base_url}/index.html"]
today = datetime.today().strftime('%Y-%m-%d')

index_html = "<h1>ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡</h1>\n<ul>"

for i, entry in enumerate(feed.entries):
    print(f"ğŸ”¹ ê¸€ {i+1}: {entry.title}")

    try:
        title = html.escape(entry.title)
        link = entry.link.replace("blog.naver.com", "m.blog.naver.com")
        date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        summary = entry.description if hasattr(entry, 'description') else "(ìš”ì•½ ì—†ìŒ)"
        slug = re.sub(r"[^\w\s-]", "", entry.title)
        slug = re.sub(r"\s+", "-", slug).strip("-")

        # ê°œë³„ ê¸€ HTML ìƒì„±
        post_html = f"""<h2>{title}</h2>
<p><strong>ì‘ì„±ì¼:</strong> {date}</p>
<p>{summary}</p>
<p><a href="{link}" target="_blank">ğŸ”— ë„¤ì´ë²„ì—ì„œ ë³´ê¸°</a></p>
"""
        post_path = f"posts/{slug}.html"
        with open(post_path, "w", encoding="utf-8") as f:
            f.write(post_html)
        print(f"âœ… {post_path} ìƒì„± ì™„ë£Œ")

        index_html += f'<li><a href="posts/{slug}.html">{title}</a></li>\n'
        urls.append(f"{base_url}/posts/{quote(slug)}.html")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

index_html += "</ul>"
with open("index.html", "w", encoding="utf-8") as f:
    f.write(index_html)
print("âœ… index.html ìƒì„± ì™„ë£Œ")

# sitemap.xml ìƒì„±
sitemap = '''<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'''
for url in urls:
    sitemap += f"  <url><loc>{url}</loc><lastmod>{today}</lastmod></url>\n"
sitemap += "</urlset>"

with open("sitemap.xml", "w", encoding="utf-8") as f:
    f.write(sitemap)
print("âœ… sitemap.xml ìƒì„± ì™„ë£Œ")

# robots.txt ìƒì„±
robots = f"""User-agent: *
Allow: /
Sitemap: {base_url}/sitemap.xml
"""

with open("robots.txt", "w", encoding="utf-8") as f:
    f.write(robots)
print("âœ… robots.txt ìƒì„± ì™„ë£Œ")
